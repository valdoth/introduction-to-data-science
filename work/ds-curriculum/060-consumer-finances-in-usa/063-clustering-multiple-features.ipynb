{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c17a3a2-ca39-41eb-bdde-015363f482bf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+3\"><strong>6.3. Clustering with Multiple Features</strong></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44101fc2-7324-4ebf-b813-5792bec0d809",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the previous lesson, we built a K-Means model to create clusters of respondents to the Survey of Consumer Finances. We made our clusters by looking at two features only, but there are hundreds of features in the dataset that we didn't take into account and that could contain valuable information. In this lesson, we'll examine all the features, selecting five to create clusters with. After we build our model and choose an appropriate number of clusters, we'll learn how to visualize multi-dimensional clusters in a 2D scatter plot using something called principal component analysis (PCA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88536d-23d7-4371-86f3-c0d45ac38c87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import wqet_grader\n",
    "from IPython.display import VimeoVideo\n",
    "from scipy.stats.mstats import trimmed_var\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "wqet_grader.init(\"Project 6 Assessment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850dccf7-e8c2-4df0-8d33-cb07e5d283b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714612789\", h=\"f4f8c10683\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66972d20-fc04-4015-8477-47e21df78913",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2837aa20-3602-48fa-a9b0-8978df695602",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fcef97-4aee-4f06-ab97-046ab45ff8ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We spent some time in the last lesson zooming in on a useful subset of the SCF, and this time, we're going to zoom in even further. One of the persistent issues we've had with this dataset is that it includes some outliers in the form of ultra-wealthy households. This didn't make much of a difference for our last analysis, but it could pose a problem in this lesson, so we're going to focus on families with net worth under \\\\$2 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41654b71-b556-43f8-a15c-2ef159055536",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714612746\", h=\"07dc57f72c\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b5845-08a4-4255-aefb-4d3d09fcfc65",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.1:** Rewrite your `wrangle` function from the last lesson so that it returns a DataFrame of households whose net worth is less than \\\\$2 million and that have been turned down for credit or feared being denied credit in the past 5 years (see `\"TURNFEAR\"`). \n",
    "\n",
    "- [<span id='technique'>Write a function in <span id='tool'>Python</span></span>.](../%40textbook/02-python-advanced.ipynb#Functions)\n",
    "- [Subset a DataFrame by selecting one or more columns in pandas.](../%40textbook/04-pandas-advanced.ipynb#Subsetting-with-Masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956d2d8-4c71-4355-aa81-d8e0e86b139f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def wrangle(filepath):\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea8d01-e0bb-4f56-8ae1-31d04ecd4622",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df = ...\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060b5a5-94f9-4998-9a5a-bd55561b484e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc7769-a70b-4f61-a5ad-9f4a7ed31949",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In this lesson, we want to make clusters using more than two features, but which of the 351 features should we choose? Often times, this decision will be made for you. For example, a stakeholder could give you a list of the features that are most important to them. If you don't have that limitation, though, another way to choose the best features for clustering is to determine which numerical features have the largest **variance**. That's what we'll do here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe3d56-51a9-409d-9f22-3da7fda16aeb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714612679\", h=\"040facf6e2\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6c0a7-871d-474b-aea4-32b016515f28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.2:** Calculate the variance for all the features in `df`, and create a Series `top_ten_var` with the 10 features with the largest variance.\n",
    "\n",
    "- [What's variance?](../%40textbook/05-pandas-summary-statistics.ipynb#Variance)\n",
    "- [Calculate the variance of a DataFrame or Series in pandas.](../%40textbook/05-pandas-summary-statistics.ipynb#Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a883e-0e9d-4bc3-9d5b-7db7bfebd177",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Calculate variance, get 10 largest features\n",
    "top_ten_var = ...\n",
    "top_ten_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93711110-494d-4b3b-bb41-e8a71603b64d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As usual, it's harder to make sense of a list like this than it would be if we visualized it, so let's make a graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43abf24-07f1-4697-8ebf-7fa9b5dbeb56",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714612647\", h=\"5ecf36a0db\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46505fff-8a73-4f9c-bb9a-90cc22d6cf70",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.3:** Use plotly express to create a horizontal bar chart of `top_ten_var`. Be sure to label your x-axis `\"Variance\"`, the y-axis `\"Feature\"`, and use the title `\"SCF: High Variance Features\"`.\n",
    "\n",
    "- [What's a bar chart?](../%40textbook/07-visualization-pandas.ipynb#Bar-Charts)\n",
    "- [Create a bar chart using plotly express.](../%40textbook/08-visualization-plotly.ipynb#Bar-Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abed052-b12f-42a6-91d9-84590c333ce6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create horizontal bar chart of `top_ten_var`\n",
    "fig = ...\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1ce17-f69b-455d-98d5-7acdeda65c10",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "One thing that we've seen throughout this project is that many of the wealth indicators are highly skewed, with a few outlier households having enormous wealth. Those outliers can affect our measure of variance. Let's see if that's the case with one of the features from `top_five_var`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74301dae-cb2b-4565-b034-1a63950d7441",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714612615\", h=\"9ae23890fc\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda134d-e2ef-42c4-a26c-d818b7e76597",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.4:** Use plotly express to create a horizontal boxplot of `\"NHNFIN\"` to determine if the values are skewed. Be sure to label the x-axis `\"Value [$]\"`, and use the title `\"Distribution of Non-home, Non-Financial Assets\"`.\n",
    "\n",
    "- [What's a boxplot?](../%40textbook/06-visualization-matplotlib.ipynb#Boxplots)\n",
    "- [Create a boxplot using plotly express.](../%40textbook/08-visualization-plotly.ipynb#Boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba45c0-af53-48c9-994c-7e5860feab01",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create a boxplot of `NHNFIN`\n",
    "fig = ...\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17041530-9b0e-4c61-b12c-62f6d75a5591",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Whoa! The dataset is massively right-skewed because of the huge outliers on the right side of the distribution. Even though we already excluded households with a high net worth with our `wrangle` function, the variance is still being distorted by some extreme outliers.\n",
    "\n",
    "The best way to deal with this is to look at the **trimmed variance**, where we remove extreme values before calculating variance. We can do this using the `trimmed_variance` function from the `SciPy` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4e499-e0a0-43f2-a76f-3ef0d714d849",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714612570\", h=\"b1be8fb750\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa8f2d-70ba-4bd3-afd7-773bad8deed0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.5:** Calculate the trimmed variance for the features in `df`. Your calculations should not include the top and bottom 10% of observations. Then create a Series `top_ten_trim_var` with the 10 features with the largest variance.\n",
    "\n",
    "- [What's trimmed variance?](../%40textbook/05-pandas-summary-statistics.ipynb#Variance)\n",
    "- [Calculate the trimmed variance of data using SciPy.](../%40textbook/05-pandas-summary-statistics.ipynb#Variance)\n",
    "- [Apply a function to a DataFrame in pandas.](../%40textbook/04-pandas-advanced.ipynb#Applying-Functions-to-DataFrames-and-Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96609cfd-1c5c-4b90-b784-12f9a8f3cbcc",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Calculate trimmed variance\n",
    "top_ten_trim_var = ...\n",
    "top_ten_trim_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b651f-da40-4764-a23b-ac3ad7b5b1c6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Okay! Now that we've got a better set of numbers, let's make another bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a95e5-a0a4-4d3a-974a-eb831df8ea08",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714611188\", h=\"d762a98b1e\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b1ce5-2529-47c3-ae84-73d7d6a0a6ce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.6:** Use plotly express to create a horizontal bar chart of `top_ten_trim_var`. Be sure to label your x-axis `\"Trimmed Variance\"`, the y-axis `\"Feature\"`, and use the title `\"SCF: High Variance Features\"`.\n",
    "\n",
    "- [What's a bar chart?](../%40textbook/07-visualization-pandas.ipynb#Bar-Charts)\n",
    "- [Create a bar chart using plotly express.](../%40textbook/08-visualization-plotly.ipynb#Bar-Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f511e06-97f2-48ed-a478-fd2d7c373a77",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create horizontal bar chart of `top_ten_trim_var`\n",
    "fig = ...\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f71e9-2185-467e-aace-428c9ba83c71",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "There are three things to notice in this plot. First, the variances have decreased a lot. In our previous chart, the x-axis went up to \\\\$80 billion; this one goes up to \\\\$12 billion. Second, the top 10 features have changed a bit. All the features relating to business ownership (`\"...BUS\"`) are gone. Finally, we can see that there are big differences in variance from feature to feature. For example, the variance for `\"WAGEINC\"` is around than \\\\$500 million, while the variance for `\"ASSET\"` is nearly \\\\$12 billion. In other words, these features have completely different scales. This is something that we'll need to address before we can make good clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7755ef-48d2-4b71-8095-91f74331fa77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714611161\", h=\"61dee490ee\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b313f-b414-4070-86b4-eaf8634ce556",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.7:** Generate a list `high_var_cols` with the column names of the  five features with the highest trimmed variance.\n",
    "\n",
    "- [What's an index?](../%40textbook/01-python-getting-started.ipynb#Working-with-Lists)\n",
    "- [Access the index of a DataFrame or Series in pandas.](../%40textbook/03-pandas-getting-started.ipynb#Working-with-DataFrame-Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e58d4-dbf0-456f-b3bb-c3391fe7080b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "high_var_cols = ...\n",
    "high_var_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b222c-aa70-4504-940b-36a69f0aa836",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf998a-89a7-498b-b5dc-9cfc74cf05b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now that we've gotten our data to a place where we can use it, we can follow the steps we've used before to build a model, starting with a feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af799809-4f58-460f-adbb-d37db7f690eb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714611148\", h=\"f7fbd4bcc5\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23506be4-2d60-4ce8-a889-05d0a7169ef8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.8:** Create the feature matrix `X`. It should contain the five columns in `high_var_cols`.\n",
    "\n",
    "- [What's a feature matrix?](../%40textbook/14-ml-classification.ipynb#Randomized-Train-Test-split)\n",
    "- [Subset a DataFrame by selecting one or more columns in pandas.](../%40textbook/04-pandas-advanced.ipynb#Subset-a-DataFrame-by-Selecting-One-or-More-Columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62da46e-9241-4ce3-a76d-65dad42079e5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "X = ...\n",
    "print(\"X shape:\", X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b8174d-0120-45fc-96b6-33f511ec07eb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa9c15-4537-4706-9cee-06c653e92eeb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f6439-f602-44e3-ab70-e7b04699dbcb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "During our EDA, we saw that we had a scale issue among our features. That issue can make it harder to cluster the data, so we'll need to fix that to help our analysis along. One strategy we can use is **standardization**, a statistical method for putting all the variables in a dataset on the same scale. Let's explore how that works here. Later, we'll incorporate it into our model pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806fee3-e666-4a04-ab1a-fb68aeb30396",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714611113\", h=\"3671a603b5\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bcf28e-e062-43e2-b7c8-cfdec3fe0707",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.9:** Create a DataFrame `X_summary` with the mean and standard deviation for all the features in `X`.\n",
    "\n",
    "- [Aggregate data in a DataFrame using one or more functions in pandas.](../%40textbook/03-pandas-getting-started.ipynb#Working-with-DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587a2c3-78a2-46f3-9b83-d314d79ccc0f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "X_summary = ...\n",
    "X_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f25a131-7d6f-42a5-b43c-700ed0516521",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "That's the information we need to standardize our data, so let's make it happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef390e-af49-41e5-b773-1d92a43c4b82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714611056\", h=\"670f6bdb78\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea251f-f38f-488e-a771-0ac1e394cf28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.10:** Create a `StandardScaler` transformer, use it to transform the data in `X`, and then put the transformed data into a DataFrame named `X_scaled`.\n",
    "\n",
    "- [What's standardization?](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#Standardization)\n",
    "- [Transform data using a transformer in scikit-learn.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#One-Hot-Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627a3d5-4e0b-4cd2-acf2-35a53d3dd278",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Instantiate transformer\n",
    "ss = ...\n",
    "\n",
    "# Transform `X`\n",
    "X_scaled_data = ...\n",
    "\n",
    "# Put `X_scaled_data` into DataFrame\n",
    "X_scaled = ...\n",
    "\n",
    "print(\"X_scaled shape:\", X_scaled.shape)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e881c-0b9f-4d64-904d-7ebac8dcb195",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As you can see, all five of the features use the same scale now. But just to make sure, let's take a look at their mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d01c11-2e61-4524-98b8-a36cafc4f357",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714611032\", h=\"1ed03c46eb\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265996f9-0f0f-48da-831a-cf72c03b1f0a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.11:** Create a DataFrame `X_scaled_summary` with the mean and standard deviation for all the features in `X_scaled`.\n",
    "\n",
    "- [Aggregate data in a DataFrame using one or more functions in pandas.](../%40textbook/03-pandas-getting-started.ipynb#Working-with-DataFrames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07600f-bd2b-4d34-837c-1992a327f5d4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "X_scaled_summary = ...\n",
    "X_scaled_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7e400-ee87-4eaf-a5e4-214d5155ad1a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "And that's what it should look like. Remember, standardization takes all the features and scales them so that they all have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40021f04-9267-4486-8c16-c9439496baaf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now that we can compare all our data on the same scale, we can start making clusters. Just like we did last time, we need to figure out how many clusters we should have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4420879-5d77-48ef-aea0-e14d2993493c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610976\", h=\"82f32af967\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc286573-a3f0-44f3-8d7c-1e4dacb06600",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.12:** Use a `for` loop to build and train a K-Means model where `n_clusters` ranges from 2 to 12 (inclusive). Your model should include a `StandardScaler`. Each time a model is trained, calculate the inertia and add it to the list `inertia_errors`, then calculate the silhouette score and add it to the list `silhouette_scores`.\n",
    "\n",
    "- [Write a `for` loop in Python.](../%40textbook/01-python-getting-started.ipynb#Working-with-for-Loops)\n",
    "- [Calculate the inertia for a model in scikit-learn.](../%40textbook/16-ml-unsupervised-learning.ipynb#Silhouette-Score)\n",
    "- [Calculate the silhouette score for a model in scikit-learn.](../%40textbook/16-ml-unsupervised-learning.ipynb#Silhouette-Score)\n",
    "- [Create a pipeline in scikit-learn.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#Creating-a-Pipeline-in-scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d01d7-6e08-41b4-8339-22d6100b7056",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "n_clusters = ...\n",
    "inertia_errors = ...\n",
    "silhouette_scores = ...\n",
    "\n",
    "# Add `for` loop to train model and calculate inertia, silhouette score.\n",
    "\n",
    "\n",
    "print(\"Inertia:\", inertia_errors[:3])\n",
    "print()\n",
    "print(\"Silhouette Scores:\", silhouette_scores[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51242f41-1f99-4f4b-ae10-6d340733efba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Just like last time, let's create an elbow plot to see how many clusters we should use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f917a8-5ee4-4bbc-869b-438cf4106c07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610940\", h=\"bacf42a282\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704c647-9954-49a3-8590-6cec568452a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.13:** Use plotly express to create a line plot that shows the values of `inertia_errors` as a function of `n_clusters`. Be sure to label your x-axis `\"Number of Clusters\"`, your y-axis `\"Inertia\"`, and use the title `\"K-Means Model: Inertia vs Number of Clusters\"`.\n",
    "\n",
    "- [What's a line plot?](../%40textbook/07-visualization-pandas.ipynb#Line-Plots)\n",
    "- [Create a line plot in plotly express.](../%40textbook/07-visualization-pandas.ipynb#Line-Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4e90b-9f3b-4737-acf9-35874ffb0480",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create line plot of `inertia_errors` vs `n_clusters`\n",
    "fig = ...\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec3fe0-30c2-4446-910e-a024660d461a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You can see that the line starts to flatten out around 4 or 5 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40026698-ff70-401b-83a7-66cbb9b7fd7d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p><b>Note:</b> We ended up using 5 clusters last time, too, but that's because we're working with very similar data. 5 clusters isn't always going to be the right choice for this type of analysis, as we'll see below.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d7f97-3f09-4b30-8644-5ee135caf3bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's make another line plot based on the silhouette scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706505a-2c5e-4575-b3f2-b812a9cdb642",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610912\", h=\"01961ee57a\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17dfd5f-08c2-49f0-8f9d-c701f34a3334",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.14:** Use plotly express to create a line plot that shows the values of `silhouette_scores` as a function of `n_clusters`. Be sure to label your x-axis `\"Number of Clusters\"`, your y-axis `\"Silhouette Score\"`, and use the title `\"K-Means Model: Silhouette Score vs Number of Clusters\"`.\n",
    "\n",
    "- [What's a line plot?](../%40textbook/07-visualization-pandas.ipynb#Line-Plots)\n",
    "- [Create a line plot in plotly express.](../%40textbook/07-visualization-pandas.ipynb#Line-Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d5ff7-160f-4352-a16e-167f9f332543",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create a line plot of `silhouette_scores` vs `n_clusters`\n",
    "fig = ...\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Number of Clusters\", yaxis_title=\"Silhouette Score\"\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5081375-af5c-4272-b466-381bfaebf82c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "This one's a little less straightforward, but we can see that the best silhouette scores occur when there are 3 or 4 clusters. \n",
    "\n",
    "Putting the information from this plot together with our inertia plot, it seems like the best setting for `n_clusters` will be 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682cffd5-d1a1-42bc-877e-8d7337dec5c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610883\", h=\"a6a0431b02\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c187019-4471-4853-83e9-709ad0a8968f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.15:** Build and train a new k-means model named `final_model`. Use the information you gained from the two plots above to set an appropriate value for the `n_clusters` argument. Once you've built and trained your model, submit it to the grader for evaluation.\n",
    "\n",
    "- [Create a pipeline in scikit-learn.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#Creating-a-Pipeline-in-scikit-learn)\n",
    "- [Fit a model to training data in scikit-learn.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#Creating-a-Pipeline-in-scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8bf469-9925-45d1-b612-611b49ff08ce",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "final_model = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4de3ae-2b2d-4c56-bf8f-9763edcb7ff2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "When you're confident in your model, submit it to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64663ced-c04c-47bf-9b38-55f2bc11005e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "wqet_grader.grade(\"Project 6 Assessment\", \"Task 6.3.14\", final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23857cb-c52b-409c-894f-16fa22e24e70",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Communicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a862054-a1e0-4b90-a489-31345b058a76",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "It's time to let everyone know how things turned out. Let's start by grabbing the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50d0b6-5833-4266-9048-ed8fb5fc54ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610862\", h=\"69ff3fb2c8\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da279cb-4920-494e-81bc-14995812e590",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.16:** Extract the labels that your `final_model` created during training and assign them to the variable `labels`.\n",
    "\n",
    "- [Access an object in a pipeline in scikit-learn.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#Accessing-an-Object-in-a-Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000db7ce-7c74-40a4-8bd0-5fb1f4f4eef9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "labels = ...\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07b845f-f52d-4b99-a95b-e1dee131686e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We're going to make a visualization, so we need to create a new DataFrame to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7082ce88-9ad0-4cb5-8e0c-cc183d361c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610842\", h=\"008a463aca\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28819fc0-a54b-45de-a2dd-90b5fe47fba1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.17:** Create a DataFrame `xgb` that contains the mean values of the features in `X` for each of the clusters in your `final_model`.\n",
    "\n",
    "- [Access an object in a pipeline in scikit-learn.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#Accessing-an-Object-in-a-Pipeline)\n",
    "- [Aggregate data using the groupby method in pandas.](../%40textbook/04-pandas-advanced.ipynb#Series-and-Groupby)\n",
    "- [Create a DataFrame from a Series in pandas.](../%40textbook/04-pandas-advanced.ipynb#Series-and-Groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b4f7e-3047-4380-803e-949747925242",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "xgb = ...\n",
    "xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489eca2a-b29a-4a7c-9861-340da579eaaf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now that we have a DataFrame, let's make a bar chart and see how our clusters differ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9cd0f-b18f-41b1-a599-a4ba0cebec65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610772\", h=\"e118407ff1\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf4842-5822-4235-877b-5a64b7f65b7b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.18:** Use plotly express to create a side-by-side bar chart from `xgb` that shows the mean of the features in `X` for each of the clusters in your `final_model`. Be sure to label the x-axis `\"Cluster\"`, the y-axis `\"Value [$]\"`, and use the title `\"Mean Household Finances by Cluster\"`.\n",
    "\n",
    "- [What's a bar chart?](../%40textbook/07-visualization-pandas.ipynb#Bar-Charts)\n",
    "- [Create a bar chart using plotly express.](../%40textbook/08-visualization-plotly.ipynb#Bar-Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1549076a-b706-4da2-aa87-0e6495988580",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create side-by-side bar chart of `xgb`\n",
    "fig = ...\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089f477-6f9a-4711-b0c2-b80a3468ebe6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Remember that our clusters are based partially on `NETWORTH`, which means that the households in the 0 cluster have the smallest net worth, and the households in the 2 cluster have the highest. Based on that, there are some interesting things to unpack here.\n",
    "\n",
    "First, take a look at the `DEBT` variable. You might think that it would scale as net worth increases, but it doesn't. The lowest amount of debt is carried by the households in cluster 2, even though the value of their houses (shown in green) is roughly the same. You can't *really* tell from this data what's going on, but one possibility might be that the people in cluster 2 have enough money to pay down their debts, but not quite enough money to leverage what they have into additional debts. The people in cluster 3, by contrast, might not need to worry about carrying debt because their net worth is so high. \n",
    "\n",
    "Finally, since we started out this project looking at home values, take a look at the relationship between `DEBT` and `HOUSES`. The value of the debt for the people in cluster 0 is higher than the value of their houses, suggesting that most of the debt being carried by those people is tied up in their mortgages — if they own a home at all. Contrast that with the other three clusters: the value of everyone else's debt is lower than the value of their homes.\n",
    "\n",
    "So all that's pretty interesting, but it's different from what we did last time, right? At this point in the last lesson, we  made a scatter plot. This was a straightforward task because we only worked with two features, so we could plot the data points in two dimensions. But now `X` has five dimensions! How can we plot this to give stakeholders a sense of our clusters?\n",
    "\n",
    "Since we're working with a computer screen, we don't have much of a choice about the number of dimensions we can use: it's got to be two. So, if we're going to do anything like the scatter plot we made before, we'll need to take our 5-dimensional data and change it into something we can look at in 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc9575-ac3d-40d1-821f-8792bd4c935d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610665\", h=\"19c9f7bf7f\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e299bd-362b-4083-a12c-2c74d51f8097",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.19:** Create a `PCA` transformer, use it to reduce the dimensionality of the data in `X` to 2, and then put the transformed data into a DataFrame named `X_pca`. The columns of `X_pca` should be named `\"PC1\"` and `\"PC2\"`.\n",
    "\n",
    "- [What's principal component analysis (PCA)?](../%40textbook/16-ml-unsupervised-learning.ipynb#Principal-Component-Analysis)\n",
    "- [Transform data using a transformer in scikit-learn.](../%40textbook/13-ml-data-pre-processing-and-production.ipynb#One-Hot-Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb222421-0aa9-4f14-86f6-cc8792620586",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Instantiate transformer\n",
    "pca = ...\n",
    "\n",
    "# Transform `X`\n",
    "X_t = ...\n",
    "\n",
    "# Put `X_t` into DataFrame\n",
    "X_pca = ...\n",
    "\n",
    "print(\"X_pca shape:\", X_pca.shape)\n",
    "X_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e30ab-646b-4160-a555-46ccacf8aba8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "So there we go: our five dimensions have been reduced to two. Let's make a scatter plot and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611c53b-7fff-400b-b0cf-fd2046e3e4af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "VimeoVideo(\"714610491\", h=\"755c66fe15\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b62258-c48b-4361-a3a6-27a251476589",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Task 6.3.20:** Use plotly express to create a scatter plot of `X_pca` using seaborn. Be sure to color the data points using the labels generated by your `final_model`. Label the x-axis `\"PC1\"`, the y-axis `\"PC2\"`, and use the title `\"PCA Representation of Clusters\"`.\n",
    "\n",
    "- [What's a scatter plot?](../%40textbook/06-visualization-matplotlib.ipynb#Scatter-Plots)\n",
    "- [Create a scatter plot using plotly express.](../%40textbook/08-visualization-plotly.ipynb#Scatter-Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ba066-9fe8-4dce-8a2d-9757974c0ac2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create scatter plot of `PC2` vs `PC1`\n",
    "fig = ...\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdffaf-d2d5-4634-a549-00087c16c086",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> You can often improve the performance of PCA by <a href=\"https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\">standardizing your data first</a>. Give it a try by including a <code>StandardScaler</code> in your transformation of <code>X</code>. How does it change the clusters in your scatter plot? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b173a-13a0-4154-99c6-1812472c4baa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "One limitation of this plot is that it's hard to explain what the axes here represent. In fact, both of them are a combination of the five features we originally had in `X`, which means this is pretty abstract. Still, it's the best way we have to show as much information as possible as an explanatory tool for people outside the data science community. \n",
    "\n",
    "So what does this graph mean? It means that we made four tightly-grouped clusters that share some key features. If we were presenting this to a group of stakeholders, it might be useful to show this graph first as a kind of warm-up, since most people understand how a two-dimensional object works. Then we could move on to a more nuanced analysis of the data.\n",
    "\n",
    "Just something to keep in mind as you continue your data science journey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b0665",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright © 2022 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
